{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ali-MH-Mansour/Document-classification/blob/main/Classification_doc_Vdhya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe8E2O_7iyQX"
      },
      "source": [
        "## **Connect to the Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I0ZTb-sqxH7",
        "outputId": "2b0e5d3b-0b86-43b2-d32f-a36262fae20a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gge2NxpEmGsT"
      },
      "source": [
        "# Functions for the data set preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOH5gupuRUiH",
        "outputId": "998a71cd-b01a-4846-a9ba-31389409b8c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "Collecting soyclustering\n",
            "  Downloading soyclustering-0.2.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: numpy>=1.1 in /usr/local/lib/python3.7/dist-packages (from soyclustering) (1.19.5)\n",
            "Installing collected packages: soyclustering\n",
            "Successfully installed soyclustering-0.2.0\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from numpy import array \n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords \n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter \n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "#-------------------------------------------------------------------------------\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize, pos_tag\n",
        "#-------------------------------------------------------------------------------\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\d+' , '', text)\n",
        "    text = remove_punctuation(text)\n",
        "    text = text.lower()\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'\\b\\w{1,3}\\b', '', text)\n",
        "    tokens = toknizing(text)\n",
        "    pos_map = {'J': 'a', 'N': 'n', 'R': 'r', 'V': 'v'}\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    lemmatiser = WordNetLemmatizer()\n",
        "    tokens = [lemmatiser.lemmatize(t.lower(), pos=pos_map.get(p[0], 'v')) for t, p in pos_tags]\n",
        "    return tokens\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "def remove_punctuation(text):\n",
        "     punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^+&*_~'''\n",
        "     no_punct = \"\"\n",
        "     for char in text:\n",
        "        if char not in punctuations:\n",
        "            no_punct = no_punct + char\n",
        "     return no_punct\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "def toknizing(text):\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = word_tokenize(text)\n",
        "  result = [i for i in tokens if not i in stop_words]\n",
        "  return result\n",
        "#-------------------------------------------------------------------------------\n",
        "def cosine_distance(u, v):\n",
        "  return np.dot(u, v) / (math.sqrt(np.dot(u, u)) * math.sqrt(np.dot(v, v)))\n",
        "#-------------------------------------------------------------------------------\n",
        "!pip install soyclustering\n",
        "from soyclustering import SphericalKMeans\n",
        "from scipy.sparse import csr_matrix\n",
        "#-------------------------------------------------------------------------------\n",
        "def spherical_kmeans(n_clusters_, list_of_words_vectors,sim_digree):\n",
        "  embeddings_matrix_csr = csr_matrix(list_of_words_vectors)\n",
        "  spherical_kmeans = SphericalKMeans( max_similar=sim_digree, init='similar_cut', \n",
        "      n_clusters = n_clusters_)\n",
        "  labels = spherical_kmeans.fit_predict(embeddings_matrix_csr)\n",
        "  centers = spherical_kmeans.cluster_centers_\n",
        "  return labels , centers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj8ww4vWj5BX"
      },
      "source": [
        "##Data sets Downolad"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "RE_file_path=\"/content/drive/...../Data/reuters-text.csv\"\n",
        "data_DF = pd.read_csv(RE_file_path)\n",
        "# rename columns\n",
        "data_DF.columns.values[0] = \"class\"\n",
        "data_DF.columns.values[1] = \"document\"\n",
        "data_DF.head()\n"
      ],
      "metadata": {
        "id": "sszdjT9EOqQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rnb1TFbGkhct",
        "outputId": "07e22d98-e241-4858-f0c8-f56c07ecd5df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-75b37b6b-b1d7-407e-96a9-ebc918d853cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\\n  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>SRI LANKA GETS USDA APPROVAL FOR WHEAT PRICE\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75b37b6b-b1d7-407e-96a9-ebc918d853cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75b37b6b-b1d7-407e-96a9-ebc918d853cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75b37b6b-b1d7-407e-96a9-ebc918d853cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   class                                           document\n",
              "0      0  ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...\n",
              "1      1  CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...\n",
              "2      2  JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...\n",
              "3      3  THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\\n  ...\n",
              "4      1  SRI LANKA GETS USDA APPROVAL FOR WHEAT PRICE\\n..."
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "BBC_file_path=\"/content/drive/MyDrive/PHD/Data/Reuters88.csv\"\n",
        "data_DF = pd.read_csv(BBC_file_path)\n",
        "\n",
        "# rename columns\n",
        "data_DF.columns.values[0] = \"class\"\n",
        "data_DF.columns.values[1] = \"document\"\n",
        "\n",
        "data_DF.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tZVrjJlmGctt",
        "outputId": "7b558309-8a77-4c84-e1fc-400a87181f4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-77d4ba07-8785-4549-b482-e03050e36489\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>asian exporter fear damage usjapan rift mount ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>china daily say vermin grain stock survey prov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>japan revise longterm energy demand downwards ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>thai trade deficit widen first quarter thailan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>lanka get usda approval wheat price food depar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77d4ba07-8785-4549-b482-e03050e36489')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-77d4ba07-8785-4549-b482-e03050e36489 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-77d4ba07-8785-4549-b482-e03050e36489');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   class                                           document\n",
              "0      0  asian exporter fear damage usjapan rift mount ...\n",
              "1      1  china daily say vermin grain stock survey prov...\n",
              "2      2  japan revise longterm energy demand downwards ...\n",
              "3      3  thai trade deficit widen first quarter thailan...\n",
              "4      1  lanka get usda approval wheat price food depar..."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Factorize class names to numbers\n",
        "data_DF['class'] = pd.factorize(data_DF['class'])[0]\n",
        "data_DF['document'] = data_DF.document.apply(lambda x: ' '.join(preprocess_text(x)))\n",
        "data_DF.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwKMpUBNjsKT"
      },
      "source": [
        "## Train embedding model on Reuters data set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train fast text model on your dataset\n",
        "import gensim\n",
        "from gensim.models import FastText, Word2Vec\n"
      ],
      "metadata": {
        "id": "zwNzHvmRkQw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6UbrjtHp0iy"
      },
      "outputs": [],
      "source": [
        "documents_as_list = data_DF['document'].tolist()\n",
        "doc_as_tokens =[]\n",
        "for doc in documents_as_list:\n",
        "  doc_as_tokens.append(doc.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt4z_IiKtO1G"
      },
      "outputs": [],
      "source": [
        "model_fasttext = FastText(doc_as_tokens, size=300, window=15, min_count=5, workers=4,sg=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model_fasttext.save(\"path/......../word2vec.model\")"
      ],
      "metadata": {
        "id": "IsM5tLu_kug7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_w2v = Word2Vec(doc_as_tokens, size=300, window=15, min_count=5, workers=4,sg=1)"
      ],
      "metadata": {
        "id": "JzPPk3H7kaI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3vs_X3xlJGb"
      },
      "source": [
        "## Create Dictionary of words & embedd doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81aCahTnKf61"
      },
      "outputs": [],
      "source": [
        "dic_w_v = {}\n",
        "all_doc_emb = []\n",
        "for doc in doc_as_tokens:\n",
        "  doc_emb = []\n",
        "  for w in doc:\n",
        "    try :\n",
        "      emb = model_fasttext.wv[w]\n",
        "      doc_emb.append(emb)\n",
        "      dic_w_v.update({w : emb})\n",
        "    except: \n",
        "      continue;\n",
        "  all_doc_emb.append(doc_emb) # doc as list of embedded words"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Averaged embeddings"
      ],
      "metadata": {
        "id": "BK4OzyIilC1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_fasttext =[]\n",
        "dzero=[0] * 300\n",
        "i=0\n",
        "for d in all_doc_emb:\n",
        "  l=len(d)\n",
        "  s=sum(d)\n",
        "  if l!=0:\n",
        "    av=s/l\n",
        "    avg_fasttext.append(av)\n",
        "  else:\n",
        "    avg_fasttext.append(dzero)\n",
        "  i=i+1"
      ],
      "metadata": {
        "id": "d4dYdauelS9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BOC"
      ],
      "metadata": {
        "id": "1lwpXi3llTdT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSThZ7Xwlk8D"
      },
      "source": [
        "## Clustering the words (concepts extraction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITdUoveQKEub"
      },
      "outputs": [],
      "source": [
        "list_of_words_vectors = list(dic_w_v.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9y9uRZfH5fY",
        "outputId": "cb400b13-36c2-459d-f8bb-d090d77b578e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The clusters details Counter({105: 298, 112: 295, 198: 287, 58: 249, 7: 233, 128: 232, 176: 213, 142: 211, 11: 204, 253: 196, 145: 196, 82: 194, 22: 187, 123: 186, 277: 185, 178: 183, 191: 181, 201: 180, 33: 180, 180: 180, 259: 178, 288: 177, 140: 177, 27: 176, 287: 175, 31: 170, 282: 168, 234: 163, 227: 161, 48: 161, 10: 160, 138: 160, 222: 160, 86: 159, 279: 158, 249: 154, 43: 154, 286: 154, 98: 151, 118: 151, 89: 150, 267: 150, 146: 149, 245: 148, 199: 147, 163: 147, 171: 146, 40: 146, 242: 146, 187: 146, 61: 145, 19: 143, 200: 143, 254: 143, 75: 141, 283: 140, 204: 139, 77: 136, 9: 136, 46: 134, 229: 133, 216: 130, 52: 129, 103: 128, 210: 128, 226: 126, 281: 126, 272: 125, 34: 125, 126: 124, 44: 123, 96: 123, 14: 122, 291: 120, 72: 119, 93: 118, 144: 116, 275: 115, 293: 115, 177: 114, 238: 111, 239: 111, 141: 110, 15: 110, 45: 110, 189: 109, 155: 108, 218: 108, 207: 108, 134: 107, 196: 107, 109: 106, 251: 106, 299: 106, 69: 104, 113: 103, 124: 101, 292: 101, 101: 100, 166: 99, 190: 99, 188: 98, 104: 97, 83: 97, 131: 96, 264: 94, 289: 94, 51: 93, 149: 92, 102: 91, 39: 91, 230: 90, 280: 90, 18: 90, 78: 90, 156: 89, 28: 88, 50: 88, 215: 87, 172: 86, 88: 86, 169: 85, 152: 84, 224: 84, 71: 84, 59: 84, 122: 84, 278: 83, 170: 83, 268: 83, 243: 82, 99: 82, 263: 81, 108: 81, 80: 81, 270: 80, 110: 80, 271: 79, 135: 79, 41: 79, 175: 78, 76: 78, 213: 78, 68: 77, 262: 77, 115: 77, 139: 76, 57: 74, 127: 73, 298: 71, 284: 71, 244: 70, 252: 70, 223: 70, 225: 69, 232: 69, 92: 68, 148: 68, 241: 67, 8: 67, 202: 67, 258: 67, 285: 66, 214: 65, 25: 64, 296: 64, 125: 63, 23: 63, 35: 63, 21: 63, 132: 63, 208: 62, 137: 62, 42: 62, 236: 61, 4: 61, 36: 61, 250: 60, 248: 60, 162: 58, 147: 57, 154: 56, 56: 56, 151: 56, 265: 56, 70: 56, 120: 56, 12: 55, 173: 55, 247: 54, 274: 54, 256: 53, 100: 52, 26: 52, 165: 52, 194: 51, 209: 51, 30: 51, 212: 51, 37: 50, 183: 50, 84: 50, 0: 50, 54: 50, 106: 49, 74: 49, 203: 49, 192: 48, 64: 48, 117: 47, 55: 47, 233: 46, 240: 45, 53: 45, 211: 45, 161: 45, 49: 44, 129: 43, 186: 43, 1: 43, 90: 42, 260: 42, 266: 42, 297: 41, 273: 41, 235: 40, 95: 39, 219: 39, 66: 39, 261: 39, 65: 39, 133: 38, 2: 38, 294: 38, 38: 37, 168: 37, 159: 37, 257: 37, 87: 36, 143: 35, 60: 35, 17: 35, 295: 33, 91: 33, 73: 33, 114: 32, 3: 31, 184: 30, 121: 30, 164: 30, 150: 30, 85: 30, 5: 29, 67: 28, 160: 28, 94: 27, 221: 27, 81: 26, 269: 26, 157: 26, 20: 25, 228: 25, 179: 25, 206: 25, 130: 24, 24: 24, 119: 24, 97: 24, 63: 23, 158: 22, 32: 22, 136: 22, 79: 22, 107: 22, 231: 21, 185: 21, 182: 20, 16: 20, 29: 20, 181: 19, 276: 19, 237: 17, 47: 17, 13: 16, 197: 15, 246: 15, 205: 15, 167: 14, 153: 14, 6: 14, 255: 14, 220: 14, 174: 12, 290: 11, 116: 11, 217: 11, 193: 9, 111: 8, 195: 5, 62: 2}) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# number of clusters\n",
        "K_clusters= 300\n",
        "sim_digree=0.3\n",
        "######### Clustering\n",
        "labels , centers = spherical_kmeans(K_clusters , list_of_words_vectors, sim_digree)\n",
        "print(\"The clusters details\", Counter(labels), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NA1crRuZT5E"
      },
      "source": [
        "# Bag of weighted Concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "869bhrJcim0p"
      },
      "source": [
        "### Documents vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGzqNobbi5u-"
      },
      "outputs": [],
      "source": [
        "#خاص بحقيبة الكلمات الاصلية\n",
        "def BOC(embeddeings_document,alpha,centers):\n",
        "  concept_occurence = 0\n",
        "  ## intilize doc array\n",
        "  CF_vector = np.zeros(len(centers)).tolist()\n",
        "  for cnt in range(len(centers)):\n",
        "    for emb_word in embeddeings_document:\n",
        "      Wsim= cosine_distance(emb_word , centers[cnt])\n",
        "      if Wsim  > alpha:\n",
        "        concept_occurence = concept_occurence + 1 #for tf\n",
        "        CF_vector[cnt] = CF_vector[cnt] + 1;\n",
        "      else:\n",
        "        continue;    \n",
        "  if concept_occurence !=0:\n",
        "    for i in CF_vector:\n",
        "      i = i / concept_occurence  #count/\n",
        "  return CF_vector\n",
        "#-------------------------------------------------------------\n",
        "def CF_IDF_BOC(documents_embeddings , alpha , centers):\n",
        "  CFs = []\n",
        "  counter = 0\n",
        "  Df = np.zeros(len(centers)).tolist() # بطول العناقيد\n",
        "  for doc in documents_embeddings: \n",
        "    CF = BOC(doc , alpha , centers )\n",
        "    for i in CF: \n",
        "      if i > 0:\n",
        "        Df[counter] = Df[counter] + 1 #  i[M-1]\n",
        "      counter = counter+1\n",
        "    counter = 0\n",
        "    CFs.append(CF)\n",
        "  #########  calculate IDF\n",
        "  IDF=[]\n",
        "  for df in Df:\n",
        "    if df!=0:\n",
        "      N=len(documents_embeddings)\n",
        "      IDF.append( math.log10( (N+1) /df ) )\n",
        "    else:\n",
        "      IDF.append(0)  \n",
        "  #Calculate Cf-IDF\n",
        "  for i in range(N):\n",
        "    l=len(CFs[i])\n",
        "    for j in range(l):\n",
        "       CFs[i][j] = CFs[i][j] * IDF[j]  #cf*idf\n",
        "  return CFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ci2bgMM3NiDu"
      },
      "outputs": [],
      "source": [
        "# Thershold similarity values\n",
        "alpha = 0.4\n",
        "\n",
        "final_embeddings  = CF_IDF_BOC(all_doc_emb , alpha , centers)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#doc2vec"
      ],
      "metadata": {
        "id": "FKrDZP03ta2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(documents_as_list)]\n",
        "model_doc2vec = Doc2Vec(documents, vector_size=300, window=10, min_count=5, workers=4 , epochs=15)"
      ],
      "metadata": {
        "id": "19eVlxI2tcXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc2vec_embeddings = model_doc2vec.docvecs"
      ],
      "metadata": {
        "id": "Ri_uBhc9zCDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TFidf"
      ],
      "metadata": {
        "id": "ObLX065kL5yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Building a TF IDF matrix out of the corpus of reviews\n",
        "vectorizer = TfidfVectorizer(sublinear_tf=False, use_idf=True, max_df=0.5,  stop_words='english')\n",
        "tfidf_vector = vectorizer.fit_transform(documents_as_list)"
      ],
      "metadata": {
        "id": "u9QtWYieMjmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tfidf_vector.todense()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oaYjWhfRAen",
        "outputId": "c9d9e572-53c7-47f7-febd-4e4931addaf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bag-of-words"
      ],
      "metadata": {
        "id": "IIUBZQdzL9_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer( max_df=0.5,  stop_words='english')\n",
        "bow_vector = vectorizer.fit_transform(documents_as_list)"
      ],
      "metadata": {
        "id": "GVXUMWt-MAYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_vector.todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mud4cV-7QlcP",
        "outputId": "195fde99-4968-4e67-bcfd-6ce0496f1ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKGo6cSoi9UP"
      },
      "source": [
        "##Train SVM for dataset calssification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_embeddings = tfidf_vector\n",
        "#final_embeddings = bow_vector\n",
        "#final_embeddings = doc2vec_embeddings\n",
        "#final_embeddings = avg_fasttext\n",
        "# final_embeddings = boc_vector"
      ],
      "metadata": {
        "id": "xH7VZSOPOyWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dag8kha4HBw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "classes = data_DF['class'].tolist()\n",
        "x_train , x_test , y_train , y_test = train_test_split(final_embeddings , classes , test_size = 0.30 , random_state = 0)\n",
        "svm =  LinearSVC( random_state= 44).fit(x_train , y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTG5Kjb2jlPU"
      },
      "source": [
        "##**Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2A-HjuAjkwf",
        "outputId": "27f9a2fc-3971-4aa4-f575-213c74dca7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The micro average-weighted f1 score =  0.9011425924993196\n"
          ]
        }
      ],
      "source": [
        "y_pred=svm.predict(x_test)\n",
        "F1 = f1_score(y_test,y_pred, average=\"macro\")\n",
        "print(\"The micro average-weighted f1 score = \", F1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsEKbQ2-emmM",
        "outputId": "b221d4bc-b4ff-47f3-ad12-d338eefec570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9372056514913658"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWoyF3_3jWQu",
        "outputId": "c9cc67a2-b846-429b-b009-d542f9cdff61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  32,    5,    2,    1,   24,    4,   19,    3],\n",
              "       [  12,   27,    4,    2,   39,    1,   11,    2],\n",
              "       [   2,    5,   49,    0,   65,    2,   47,    5],\n",
              "       [   6,    5,    4,    5,   29,    2,    6,    1],\n",
              "       [   4,    5,    9,    0,  505,    8,  128,    2],\n",
              "       [   2,    0,    4,    1,   32,   64,   25,    8],\n",
              "       [   6,    3,    5,    1,  151,    7, 1046,    0],\n",
              "       [   6,    1,    2,    0,   44,   22,   10,   26]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa_s-at68gVi",
        "outputId": "7ecaa057-c11f-446c-937e-4d185b5522b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.36      0.51       117\n",
            "           1       0.51      0.57      0.53       152\n",
            "           2       0.61      0.90      0.73       177\n",
            "           3       0.84      0.82      0.83       109\n",
            "           4       0.61      0.44      0.51       113\n",
            "\n",
            "    accuracy                           0.64       668\n",
            "   macro avg       0.68      0.62      0.62       668\n",
            "weighted avg       0.67      0.64      0.62       668\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OaUTtmJHtZI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VdHP9yTsoiKs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Classification_doc_Vdhya.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}